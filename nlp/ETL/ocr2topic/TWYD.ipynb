{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "308d03de-6bbe-49ef-9f0e-ba5fe765de06",
   "metadata": {},
   "source": [
    "# Upload to Qdrant\n",
    "\n",
    "Upload `.md` files to vector-database using [TWYD API](https://twyd.kubeapps.alquimiaai.hostmydemo.online/docs#/).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0b173d-7401-4135-ae40-880836bda1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931d81e8-3c9a-4491-9079-78bb8344419f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed658372-bc21-48cf-a4b3-8a7fc98eee51",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONFIGURATION\n",
    "\n",
    "## ENV VARIABLES (SETTED)\n",
    "TWYD_URL = os.environ.get(\"TWYD_URL\")\n",
    "TWYD_TOKEN = os.environ.get(\"TWYD_TOKEN\")\n",
    "DIR_PATH=\"ocr-output/\"\n",
    "\n",
    "## VARIABLES (DYNAMIC)\n",
    "TWYD_TOPIC_ID = os.environ.get(\"topic_id\")\n",
    "TEXT_EMBEDDER = os.environ.get(\"embedding_model\",\"nomic-ai/nomic-embed-text-v1\")\n",
    "MAX_TOKENS = 8192\n",
    "# API configuration\n",
    "headers = {\n",
    "    'Authorization': f'Bearer {TWYD_TOKEN}'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ba39a3-6db8-4e54-989d-6bc480040129",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(TEXT_EMBEDDER, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d461fd-4ff6-4478-9b67-360f5892b436",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the tokenizer\n",
    "def get_tokens_from_file(file_path, tokenizer):\n",
    "    \"\"\"Tokenize text in .md file and return the number of tokens.\"\"\"\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    return len(tokens)\n",
    "\n",
    "def calculate_optimal_chunk_size(total_tokens):\n",
    "    \"\"\"Calculates optimal chunk size based on total tokens.\"\"\"\n",
    "\n",
    "    end=32\n",
    "    for i in range(0,end+2,2):\n",
    "        try:\n",
    "            chunks = i\n",
    "            chunk_size = total_tokens/chunks\n",
    "        except ZeroDivisionError:\n",
    "            chunks = 1\n",
    "            chunk_size = total_tokens\n",
    "\n",
    "        if chunk_size < MAX_TOKENS:\n",
    "            break\n",
    "\n",
    "    return int(min(MAX_TOKENS, chunk_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84717d4f-5eab-4d3e-bcca-c9b85fbe5566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Inicializar o cargar status.json ---\n",
    "status_path = os.path.join(DIR_PATH, \"status.json\")\n",
    "if os.path.exists(status_path):\n",
    "    with open(status_path, 'r', encoding='utf-8') as f:\n",
    "        status_list = json.load(f)\n",
    "else:\n",
    "    status_list = []\n",
    "\n",
    "def save_status():\n",
    "    with open(status_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(status_list, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "def get_tokens_from_file(file_path, tokenizer):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    return len(tokenizer.tokenize(text))\n",
    "\n",
    "def calculate_optimal_chunk_size(total_tokens):\n",
    "    for chunks in range(1, 34, 2):\n",
    "        chunk_size = total_tokens / chunks if chunks else total_tokens\n",
    "        if chunk_size < MAX_TOKENS:\n",
    "            return int(min(MAX_TOKENS, chunk_size))\n",
    "    return MAX_TOKENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e84299-fd17-4ff5-a33c-efd4a850902a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Recorrer todos los archivos .md\n",
    "for root, dirs, files in os.walk(DIR_PATH):\n",
    "    for filename in files:\n",
    "        if not filename.lower().endswith('.md'):\n",
    "            continue\n",
    "\n",
    "        file_path = os.path.join(root, filename)\n",
    "        entry = {\n",
    "            \"file\": filename,\n",
    "            \"status\": None,\n",
    "            \"error\": None,\n",
    "            \"topic_id\": None\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            # 1) Upload\n",
    "            with open(file_path, 'rb') as fp:\n",
    "                files_payload = {'file': (filename, fp, 'text/markdown')}\n",
    "                resp = requests.post(\n",
    "                    f'https://{TWYD_URL}/api/files/upload',\n",
    "                    files=files_payload,\n",
    "                    headers=headers\n",
    "                )\n",
    "            resp.raise_for_status()\n",
    "            file_id = resp.json().get(\"id\")\n",
    "            if not file_id:\n",
    "                raise ValueError(\"No se devolvió 'id' al subir el archivo\")\n",
    "\n",
    "            # 2) Calcular chunks\n",
    "            total_tokens = get_tokens_from_file(file_path, tokenizer)\n",
    "            chunk_size = calculate_optimal_chunk_size(total_tokens)\n",
    "            \n",
    "            json_body = {\n",
    "                \"separators\": [\"# \",\"## \",\"### \",\"#### \",\"##### \",\"\\n\\n\",\"\\n\",\"> \",\"- \",\"* \",\"---\"],\n",
    "                \"isSeparatorRegex\": False,\n",
    "                \"chunkSize\": chunk_size,\n",
    "                \"chunkOverlap\": int(chunk_size * 0.05),\n",
    "                \"keepSeparator\": True,\n",
    "                \"addStartIndex\": False,\n",
    "                \"stripWhitespace\": True\n",
    "            }\n",
    "\n",
    "            # 3) Associate\n",
    "            assoc_resp = requests.put(\n",
    "                f\"https://{TWYD_URL}.alquimiaai.hostmydemo.online/api/topics/{TWYD_TOPIC_ID}/add/{file_id}\",\n",
    "                headers={**headers, 'Content-Type': 'application/json'},\n",
    "                json=json_body\n",
    "            )\n",
    "            assoc_resp.raise_for_status()\n",
    "\n",
    "            # Éxito\n",
    "            entry[\"status\"]   = \"success\"\n",
    "            entry[\"topic_id\"] = TWYD_TOPIC_ID\n",
    "\n",
    "            print(f\"✅ {filename} → topic {TWYD_TOPIC_ID}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            # Capturamos cualquier error\n",
    "            entry[\"status\"] = \"error\"\n",
    "            entry[\"error\"]  = str(e)\n",
    "            print(f\"❌ {filename}: {e}\")\n",
    "\n",
    "        # Guardar en status list y persistir\n",
    "        status_list.append(entry)\n",
    "        save_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acb71d7-b399-49ea-8e4e-80d452f307a3",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
